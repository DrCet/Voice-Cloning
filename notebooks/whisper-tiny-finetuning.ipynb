{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:22:55.357734Z","iopub.execute_input":"2025-03-27T17:22:55.358186Z","iopub.status.idle":"2025-03-27T17:22:55.389014Z","shell.execute_reply.started":"2025-03-27T17:22:55.358155Z","shell.execute_reply":"2025-03-27T17:22:55.387536Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375c63507e764296905b254d8310cdb3"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"from transformers.models.whisper.tokenization_whisper import TO_LANGUAGE_CODE\n\n# show all supported languages\nTO_LANGUAGE_CODE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:33:18.776454Z","iopub.execute_input":"2025-03-27T16:33:18.776880Z","iopub.status.idle":"2025-03-27T16:33:24.689632Z","shell.execute_reply.started":"2025-03-27T16:33:18.776847Z","shell.execute_reply":"2025-03-27T16:33:24.688762Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'english': 'en',\n 'chinese': 'zh',\n 'german': 'de',\n 'spanish': 'es',\n 'russian': 'ru',\n 'korean': 'ko',\n 'french': 'fr',\n 'japanese': 'ja',\n 'portuguese': 'pt',\n 'turkish': 'tr',\n 'polish': 'pl',\n 'catalan': 'ca',\n 'dutch': 'nl',\n 'arabic': 'ar',\n 'swedish': 'sv',\n 'italian': 'it',\n 'indonesian': 'id',\n 'hindi': 'hi',\n 'finnish': 'fi',\n 'vietnamese': 'vi',\n 'hebrew': 'he',\n 'ukrainian': 'uk',\n 'greek': 'el',\n 'malay': 'ms',\n 'czech': 'cs',\n 'romanian': 'ro',\n 'danish': 'da',\n 'hungarian': 'hu',\n 'tamil': 'ta',\n 'norwegian': 'no',\n 'thai': 'th',\n 'urdu': 'ur',\n 'croatian': 'hr',\n 'bulgarian': 'bg',\n 'lithuanian': 'lt',\n 'latin': 'la',\n 'maori': 'mi',\n 'malayalam': 'ml',\n 'welsh': 'cy',\n 'slovak': 'sk',\n 'telugu': 'te',\n 'persian': 'fa',\n 'latvian': 'lv',\n 'bengali': 'bn',\n 'serbian': 'sr',\n 'azerbaijani': 'az',\n 'slovenian': 'sl',\n 'kannada': 'kn',\n 'estonian': 'et',\n 'macedonian': 'mk',\n 'breton': 'br',\n 'basque': 'eu',\n 'icelandic': 'is',\n 'armenian': 'hy',\n 'nepali': 'ne',\n 'mongolian': 'mn',\n 'bosnian': 'bs',\n 'kazakh': 'kk',\n 'albanian': 'sq',\n 'swahili': 'sw',\n 'galician': 'gl',\n 'marathi': 'mr',\n 'punjabi': 'pa',\n 'sinhala': 'si',\n 'khmer': 'km',\n 'shona': 'sn',\n 'yoruba': 'yo',\n 'somali': 'so',\n 'afrikaans': 'af',\n 'occitan': 'oc',\n 'georgian': 'ka',\n 'belarusian': 'be',\n 'tajik': 'tg',\n 'sindhi': 'sd',\n 'gujarati': 'gu',\n 'amharic': 'am',\n 'yiddish': 'yi',\n 'lao': 'lo',\n 'uzbek': 'uz',\n 'faroese': 'fo',\n 'haitian creole': 'ht',\n 'pashto': 'ps',\n 'turkmen': 'tk',\n 'nynorsk': 'nn',\n 'maltese': 'mt',\n 'sanskrit': 'sa',\n 'luxembourgish': 'lb',\n 'myanmar': 'my',\n 'tibetan': 'bo',\n 'tagalog': 'tl',\n 'malagasy': 'mg',\n 'assamese': 'as',\n 'tatar': 'tt',\n 'hawaiian': 'haw',\n 'lingala': 'ln',\n 'hausa': 'ha',\n 'bashkir': 'ba',\n 'javanese': 'jw',\n 'sundanese': 'su',\n 'cantonese': 'yue',\n 'burmese': 'my',\n 'valencian': 'ca',\n 'flemish': 'nl',\n 'haitian': 'ht',\n 'letzeburgesch': 'lb',\n 'pushto': 'ps',\n 'panjabi': 'pa',\n 'moldavian': 'ro',\n 'moldovan': 'ro',\n 'sinhalese': 'si',\n 'castilian': 'es',\n 'mandarin': 'zh'}"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\n# Load processor from pretrained checkpoint, setting the language to \"vietnamese\"\n\nprocessor = WhisperProcessor.from_pretrained(\n    \"openai/whisper-tiny\", language=\"vietnamese\", task=\"transcribe\"\n)   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:36:23.934279Z","iopub.execute_input":"2025-03-27T16:36:23.934866Z","iopub.status.idle":"2025-03-27T16:36:30.553980Z","shell.execute_reply.started":"2025-03-27T16:36:23.934837Z","shell.execute_reply":"2025-03-27T16:36:30.553001Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ce6a5cb2f6c43b38c63be8fc67a0c23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb940fb85dd64e72a67e19079ec1e3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"224a67f6a0e1453aafab77375fe3c1df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ddf415b60e4dd799698cc4a91e6cc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dfffabb8e594f05b41de3b011d42bc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0469f3e28dfa476ab0aa9752bd18f02e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a220518284744e2893215649580c00c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb7013917ae747cab9541de544786f90"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\nimport datasets\n\ndataset = load_dataset(\"Cets/audio-logs-vn-1\")\nprint(dataset)\ndataset['train'].features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:37:50.327132Z","iopub.execute_input":"2025-03-27T16:37:50.327734Z","iopub.status.idle":"2025-03-27T16:38:14.205712Z","shell.execute_reply.started":"2025-03-27T16:37:50.327700Z","shell.execute_reply":"2025-03-27T16:38:14.204873Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/468 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9827ee6170714635a49ad116d93bd17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/342M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe8e56d484d437588cb448ff30d199d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/345M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48c811ffe7d4e9f94ffc085b5e82bc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/173M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f56b346c53a48af83fae0aa4fc95f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1913 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e8e0f0cca24c8c8a764b80b78f296e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/479 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d63108c2f6849e3b257e6721fb58ef0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'text'],\n        num_rows: 1913\n    })\n    test: Dataset({\n        features: ['audio', 'text'],\n        num_rows: 479\n    })\n})\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n 'text': Value(dtype='string', id=None)}"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Sampling rate was already 16kHz, this is just for demonstrating how to deal with other situations\nsampling_rate = processor.feature_extractor.sampling_rate\ndataset = dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=sampling_rate))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:40:30.060996Z","iopub.execute_input":"2025-03-27T16:40:30.061310Z","iopub.status.idle":"2025-03-27T16:40:30.073291Z","shell.execute_reply.started":"2025-03-27T16:40:30.061285Z","shell.execute_reply":"2025-03-27T16:40:30.072147Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"text\"],\n    )\n    # compute input length of audio sample in seconds\n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:44:07.385069Z","iopub.execute_input":"2025-03-27T16:44:07.385407Z","iopub.status.idle":"2025-03-27T16:44:07.390445Z","shell.execute_reply.started":"2025-03-27T16:44:07.385382Z","shell.execute_reply":"2025-03-27T16:44:07.389469Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Apply the data preparation function to all of our training examples\ndataset = dataset.map(\n    prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=1\n)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T16:44:09.123095Z","iopub.execute_input":"2025-03-27T16:44:09.123420Z","iopub.status.idle":"2025-03-27T16:45:27.046166Z","shell.execute_reply.started":"2025-03-27T16:44:09.123395Z","shell.execute_reply":"2025-03-27T16:45:27.044695Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1913 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b50ea7cb02874e9caad75b50876d4dfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/479 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb892f2b0054522bf4bec54ac86854d"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:03:40.676398Z","iopub.execute_input":"2025-03-27T17:03:40.676960Z","iopub.status.idle":"2025-03-27T17:03:40.683291Z","shell.execute_reply.started":"2025-03-27T17:03:40.676926Z","shell.execute_reply":"2025-03-27T17:03:40.682279Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 1913\n    })\n    test: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 479\n    })\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Define data collator","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch\n\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:04:19.061334Z","iopub.execute_input":"2025-03-27T17:04:19.061759Z","iopub.status.idle":"2025-03-27T17:04:19.070196Z","shell.execute_reply.started":"2025-03-27T17:04:19.061725Z","shell.execute_reply":"2025-03-27T17:04:19.068938Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Define metrics","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install evaluate\n!pip install jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:07:43.111181Z","iopub.execute_input":"2025-03-27T17:07:43.111538Z","iopub.status.idle":"2025-03-27T17:07:54.562878Z","shell.execute_reply.started":"2025-03-27T17:07:43.111511Z","shell.execute_reply":"2025-03-27T17:07:54.561415Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n\n    # we do not want to group tokens when computing the metrics\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n\n    # compute orthographic wer\n    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    # compute normalised WER\n    pred_str_norm = [pred.lower() for pred in pred_str]\n    label_str_norm = [label.lower() for label in label_str]\n    # filtering step to only evaluate the samples that correspond to non-zero references:\n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n\n    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:07:58.868309Z","iopub.execute_input":"2025-03-27T17:07:58.868751Z","iopub.status.idle":"2025-03-27T17:07:59.445838Z","shell.execute_reply.started":"2025-03-27T17:07:58.868716Z","shell.execute_reply":"2025-03-27T17:07:59.444824Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n\nfrom functools import partial\n\n# disable cache during training since it's incompatible with gradient checkpointing\nmodel.config.use_cache = False\n\n# set language and task for generation and re-enable cache\nmodel.generate = partial(\n    model.generate, language=\"vietnamese\", task=\"transcribe\", use_cache=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:09:30.653172Z","iopub.execute_input":"2025-03-27T17:09:30.653763Z","iopub.status.idle":"2025-03-27T17:09:32.297861Z","shell.execute_reply.started":"2025-03-27T17:09:30.653727Z","shell.execute_reply":"2025-03-27T17:09:32.296765Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a1057a1bda84773bfc67f24d3480753"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35fd92e2dacb45ac8c10e0991eacfc19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13be2ee52c8549d6bfde20c2b42a1bee"}},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Training args","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\n\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/whisper-tiny-vn-1\",  # name on the HF Hub\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n    learning_rate=1e-5,\n    lr_scheduler_type=\"constant_with_warmup\",\n    warmup_steps=50,\n    max_steps=500,  # increase to 4000 if you have your own GPU or a Colab paid plan\n    gradient_checkpointing=True,\n    fp16=True,\n    fp16_full_eval=True,\n    eval_strategy=\"steps\",\n    per_device_eval_batch_size=16,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=25,\n    eval_steps=25,\n    logging_steps=25,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:23:34.521239Z","iopub.execute_input":"2025-03-27T17:23:34.521659Z","iopub.status.idle":"2025-03-27T17:23:34.528958Z","shell.execute_reply.started":"2025-03-27T17:23:34.521612Z","shell.execute_reply":"2025-03-27T17:23:34.527738Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    processing_class=processor,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:23:51.770455Z","iopub.execute_input":"2025-03-27T17:23:51.770865Z","iopub.status.idle":"2025-03-27T17:23:51.896107Z","shell.execute_reply.started":"2025-03-27T17:23:51.770833Z","shell.execute_reply":"2025-03-27T17:23:51.895108Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T17:23:56.469961Z","iopub.execute_input":"2025-03-27T17:23:56.470311Z","iopub.status.idle":"2025-03-27T17:24:54.949763Z","shell.execute_reply.started":"2025-03-27T17:23:56.470286Z","shell.execute_reply":"2025-03-27T17:24:54.948026Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/500 : < :, Epoch 0.01/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   2156\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2520\u001b[0m                     )\n\u001b[1;32m   2521\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3686\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3689\u001b[0m             \u001b[0;31m# Finally we need to normalize the loss for reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2248\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    305\u001b[0m             )\n\u001b[1;32m    306\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    302\u001b[0m             ) if torch.amp.is_autocast_available(ctx.device_type) else contextlib.nullcontext()\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_autocast_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_autocast_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdetached_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}