{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "DH5KB14VvMUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHTajYN0tRyL",
        "outputId": "f6a3366e-014b-4e62-f8da-597d0e4139ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'finetune-hf-vits' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ylacombe/finetune-hf-vits\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd finetune-hf-vits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXugYgjWuCRU",
        "outputId": "f15d417f-af63-4955-ccb0-ede8b6efeca9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/finetune-hf-vits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R7hjROSMuLsm",
        "outputId": "1f404fa0-a682-4bc1-e937-9a1ef0a5272d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.35.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.50.3)\n",
            "Collecting datasets>=2.14.7 (from datasets[audio]>=2.14.7->-r requirements.txt (line 2))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.19.8)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.1->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.24.1->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.24.1->-r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.11.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.25.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.13.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: soxr>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.5.0.post1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (6.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.1->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.1->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.1->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.24.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.7->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->datasets[audio]>=2.14.7->-r requirements.txt (line 2)) (3.6.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "34NfOao9uNP9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-HjAjr9u3P0",
        "outputId": "0388ef18-d104-4098-ca4a-f61bf440ea2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `finetune-vits` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `finetune-vits`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd monotonic_align"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-TlTQ0pu54T",
        "outputId": "014d193d-4776-4bd1-b684-40fd73a0741b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/finetune-hf-vits/monotonic_align\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir monotonic_align"
      ],
      "metadata": {
        "id": "eYUp8MiCvPbG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py build_ext --inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t_CKSzEovRbA",
        "outputId": "b19e4138-89fd-4ad1-b07b-a74e61c3cf7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling core.pyx because it changed.\n",
            "[1/1] Cythonizing core.pyx\n",
            "/usr/local/lib/python3.11/dist-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /content/finetune-hf-vits/monotonic_align/core.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "performance hint: core.pyx:7:5: Exception check on 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n",
            "performance hint: core.pyx:38:6: Exception check on 'maximum_path_c' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_c' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_c' to allow an error code to be returned.\n",
            "performance hint: core.pyx:42:21: Exception check after calling 'maximum_path_each' will always require the GIL to be acquired.\n",
            "Possible solutions:\n",
            "\t1. Declare 'maximum_path_each' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
            "\t2. Use an 'int' return type on 'maximum_path_each' to allow an error code to be returned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcEiAoIevUWe",
        "outputId": "1f11270e-0e82-4dcc-958a-6a84d173acb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/finetune-hf-vits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/isi-nlp/uroman.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr1Lw6xFvjYh",
        "outputId": "ab2f0b29-e068-4e45-e784-3b89b5ddac6d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'uroman'...\n",
            "remote: Enumerating objects: 579, done.\u001b[K\n",
            "remote: Counting objects: 100% (295/295), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 579 (delta 189), reused 263 (delta 164), pack-reused 284 (from 1)\u001b[K\n",
            "Receiving objects: 100% (579/579), 5.07 MiB | 19.50 MiB/s, done.\n",
            "Resolving deltas: 100% (321/321), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd uroman"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS8cnGuGv3LR",
        "outputId": "42718789-53e6-4f23-9dfa-91158bcc91b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/finetune-hf-vits/uroman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export UROMAN=$(pwd)"
      ],
      "metadata": {
        "id": "HlyphjUAv5oM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKk8eu5qv62q",
        "outputId": "e02427e9-7306-4e9c-b64b-06d32e04ef90"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/finetune-hf-vits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection"
      ],
      "metadata": {
        "id": "MzpZAgg4wAHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_original_discriminator_checkpoint.py --language_code vie --pytorch_dump_folder_path mms-tts-vie-own --push_to_hub mms-tts-vie-own"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d5wV_fhVv95T",
        "outputId": "7cb4729f-ca0b-4230-d528-b2a706e9c42d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-03 17:46:27.737433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743702388.093554    3941 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743702388.188716    3941 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-03 17:46:28.885411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "D_100000.pth: 100% 561M/561M [00:07<00:00, 80.1MB/s]\n",
            "config.json: 100% 1.64k/1.64k [00:00<00:00, 10.2MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/config.json\n",
            "Model config VitsConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"architectures\": [\n",
            "    \"VitsModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"depth_separable_channels\": 2,\n",
            "  \"depth_separable_num_layers\": 3,\n",
            "  \"discriminator_kernel_size\": 5,\n",
            "  \"discriminator_period_channels\": [\n",
            "    1,\n",
            "    32,\n",
            "    128,\n",
            "    512,\n",
            "    1024\n",
            "  ],\n",
            "  \"discriminator_periods\": [\n",
            "    2,\n",
            "    3,\n",
            "    5,\n",
            "    7,\n",
            "    11\n",
            "  ],\n",
            "  \"discriminator_scale_channels\": [\n",
            "    1,\n",
            "    16,\n",
            "    64,\n",
            "    256,\n",
            "    1024\n",
            "  ],\n",
            "  \"discriminator_stride\": 3,\n",
            "  \"duration_predictor_dropout\": 0.5,\n",
            "  \"duration_predictor_filter_channels\": 256,\n",
            "  \"duration_predictor_flow_bins\": 10,\n",
            "  \"duration_predictor_kernel_size\": 3,\n",
            "  \"duration_predictor_num_flows\": 4,\n",
            "  \"duration_predictor_tail_bound\": 5.0,\n",
            "  \"ffn_dim\": 768,\n",
            "  \"ffn_kernel_size\": 3,\n",
            "  \"flow_size\": 192,\n",
            "  \"hidden_act\": \"relu\",\n",
            "  \"hidden_dropout\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"hop_length\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"layerdrop\": 0.1,\n",
            "  \"leaky_relu_slope\": 0.1,\n",
            "  \"model_type\": \"vits\",\n",
            "  \"noise_scale\": 0.667,\n",
            "  \"noise_scale_duration\": 0.8,\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"num_speakers\": 1,\n",
            "  \"posterior_encoder_num_wavenet_layers\": 16,\n",
            "  \"prior_encoder_num_flows\": 4,\n",
            "  \"prior_encoder_num_wavenet_layers\": 4,\n",
            "  \"resblock_dilation_sizes\": [\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ]\n",
            "  ],\n",
            "  \"resblock_kernel_sizes\": [\n",
            "    3,\n",
            "    7,\n",
            "    11\n",
            "  ],\n",
            "  \"sampling_rate\": 16000,\n",
            "  \"segment_size\": 8192,\n",
            "  \"speaker_embedding_size\": 0,\n",
            "  \"speaking_rate\": 1.0,\n",
            "  \"spectrogram_bins\": 513,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.50.3\",\n",
            "  \"upsample_initial_channel\": 512,\n",
            "  \"upsample_kernel_sizes\": [\n",
            "    16,\n",
            "    16,\n",
            "    4,\n",
            "    4\n",
            "  ],\n",
            "  \"upsample_rates\": [\n",
            "    8,\n",
            "    8,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"use_bias\": true,\n",
            "  \"use_stochastic_duration_prediction\": true,\n",
            "  \"vocab_size\": 95,\n",
            "  \"wavenet_dilation_rate\": 1,\n",
            "  \"wavenet_dropout\": 0.0,\n",
            "  \"wavenet_kernel_size\": 5,\n",
            "  \"window_size\": 4\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/config.json\n",
            "Model config VitsConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"architectures\": [\n",
            "    \"VitsModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"depth_separable_channels\": 2,\n",
            "  \"depth_separable_num_layers\": 3,\n",
            "  \"duration_predictor_dropout\": 0.5,\n",
            "  \"duration_predictor_filter_channels\": 256,\n",
            "  \"duration_predictor_flow_bins\": 10,\n",
            "  \"duration_predictor_kernel_size\": 3,\n",
            "  \"duration_predictor_num_flows\": 4,\n",
            "  \"duration_predictor_tail_bound\": 5.0,\n",
            "  \"ffn_dim\": 768,\n",
            "  \"ffn_kernel_size\": 3,\n",
            "  \"flow_size\": 192,\n",
            "  \"hidden_act\": \"relu\",\n",
            "  \"hidden_dropout\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"layerdrop\": 0.1,\n",
            "  \"leaky_relu_slope\": 0.1,\n",
            "  \"model_type\": \"vits\",\n",
            "  \"noise_scale\": 0.667,\n",
            "  \"noise_scale_duration\": 0.8,\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"num_speakers\": 1,\n",
            "  \"posterior_encoder_num_wavenet_layers\": 16,\n",
            "  \"prior_encoder_num_flows\": 4,\n",
            "  \"prior_encoder_num_wavenet_layers\": 4,\n",
            "  \"resblock_dilation_sizes\": [\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      1,\n",
            "      3,\n",
            "      5\n",
            "    ]\n",
            "  ],\n",
            "  \"resblock_kernel_sizes\": [\n",
            "    3,\n",
            "    7,\n",
            "    11\n",
            "  ],\n",
            "  \"sampling_rate\": 16000,\n",
            "  \"speaker_embedding_size\": 0,\n",
            "  \"speaking_rate\": 1.0,\n",
            "  \"spectrogram_bins\": 513,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.50.3\",\n",
            "  \"upsample_initial_channel\": 512,\n",
            "  \"upsample_kernel_sizes\": [\n",
            "    16,\n",
            "    16,\n",
            "    4,\n",
            "    4\n",
            "  ],\n",
            "  \"upsample_rates\": [\n",
            "    8,\n",
            "    8,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"use_bias\": true,\n",
            "  \"use_stochastic_duration_prediction\": true,\n",
            "  \"vocab_size\": 95,\n",
            "  \"wavenet_dilation_rate\": 1,\n",
            "  \"wavenet_dropout\": 0.0,\n",
            "  \"wavenet_kernel_size\": 5,\n",
            "  \"window_size\": 4\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 145M/145M [00:01<00:00, 73.1MB/s]\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/model.safetensors\n",
            "All model checkpoint weights were used when initializing VitsModel.\n",
            "\n",
            "All the weights of VitsModel were initialized from the model checkpoint at facebook/mms-tts-vie.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use VitsModel for predictions without further training.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "model loaded: 46.7M params\n",
            "tokenizer_config.json: 100% 289/289 [00:00<00:00, 1.82MB/s]\n",
            "vocab.json: 100% 1.15k/1.15k [00:00<00:00, 6.64MB/s]\n",
            "special_tokens_map.json: 100% 49.0/49.0 [00:00<00:00, 218kB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/vocab.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--mms-tts-vie/snapshots/b58928d033932a49aa8e3d6cf11625b25fe928d2/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file chat_template.jinja from cache at None\n",
            "Configuration saved in mms-tts-vie-own/config.json\n",
            "Model weights saved in mms-tts-vie-own/model.safetensors\n",
            "tokenizer config file saved in mms-tts-vie-own/tokenizer_config.json\n",
            "Special tokens file saved in mms-tts-vie-own/special_tokens_map.json\n",
            "added tokens file saved in mms-tts-vie-own/added_tokens.json\n",
            "Feature extractor saved in mms-tts-vie-own/preprocessor_config.json\n",
            "Pushing to the hub...\n",
            "Configuration saved in mms-tts-vie-own/config.json\n",
            "Model weights saved in mms-tts-vie-own/model.safetensors\n",
            "Uploading the following files to Cets/mms-tts-vie-own: README.md,model.safetensors,config.json\n",
            "model.safetensors: 100% 332M/332M [00:07<00:00, 47.1MB/s]\n",
            "README.md: 100% 5.17k/5.17k [00:00<00:00, 20.4MB/s]\n",
            "tokenizer config file saved in mms-tts-vie-own/tokenizer_config.json\n",
            "Special tokens file saved in mms-tts-vie-own/special_tokens_map.json\n",
            "added tokens file saved in mms-tts-vie-own/added_tokens.json\n",
            "Uploading the following files to Cets/mms-tts-vie-own: special_tokens_map.json,tokenizer_config.json,README.md,vocab.json,added_tokens.json\n",
            "Feature extractor saved in mms-tts-vie-own/preprocessor_config.json\n",
            "Uploading the following files to Cets/mms-tts-vie-own: preprocessor_config.json,README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune"
      ],
      "metadata": {
        "id": "l-sBUs-4xIr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_vits_finetuning.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mEDQNGv1xIgU",
        "outputId": "0723fa1e-86c9-4140-e510-4ba5ebed386b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-03 17:48:26.102615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743702506.147152    4451 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743702506.159788    4451 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-03 17:48:26.197910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: run_vits_finetuning.py [-h] --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                              [--config_name CONFIG_NAME] [--tokenizer_name TOKENIZER_NAME]\n",
            "                              [--feature_extractor_name FEATURE_EXTRACTOR_NAME]\n",
            "                              [--cache_dir CACHE_DIR] [--use_fast_tokenizer [USE_FAST_TOKENIZER]]\n",
            "                              [--no_use_fast_tokenizer] [--model_revision MODEL_REVISION]\n",
            "                              [--token TOKEN] [--use_auth_token [USE_AUTH_TOKEN]]\n",
            "                              [--trust_remote_code [TRUST_REMOTE_CODE]]\n",
            "                              [--override_speaker_embeddings [OVERRIDE_SPEAKER_EMBEDDINGS]]\n",
            "                              [--override_vocabulary_embeddings [OVERRIDE_VOCABULARY_EMBEDDINGS]]\n",
            "                              [--project_name PROJECT_NAME] [--dataset_name DATASET_NAME]\n",
            "                              [--dataset_config_name DATASET_CONFIG_NAME]\n",
            "                              [--overwrite_cache [OVERWRITE_CACHE]]\n",
            "                              [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
            "                              [--max_train_samples MAX_TRAIN_SAMPLES]\n",
            "                              [--max_eval_samples MAX_EVAL_SAMPLES]\n",
            "                              [--audio_column_name AUDIO_COLUMN_NAME]\n",
            "                              [--text_column_name TEXT_COLUMN_NAME]\n",
            "                              [--speaker_id_column_name SPEAKER_ID_COLUMN_NAME]\n",
            "                              [--filter_on_speaker_id FILTER_ON_SPEAKER_ID]\n",
            "                              [--max_tokens_length MAX_TOKENS_LENGTH]\n",
            "                              [--max_duration_in_seconds MAX_DURATION_IN_SECONDS]\n",
            "                              [--min_duration_in_seconds MIN_DURATION_IN_SECONDS]\n",
            "                              [--preprocessing_only [PREPROCESSING_ONLY]]\n",
            "                              [--train_split_name TRAIN_SPLIT_NAME]\n",
            "                              [--eval_split_name EVAL_SPLIT_NAME]\n",
            "                              [--do_lower_case [DO_LOWER_CASE]] [--do_normalize [DO_NORMALIZE]]\n",
            "                              [--full_generation_sample_text FULL_GENERATION_SAMPLE_TEXT]\n",
            "                              [--uroman_path UROMAN_PATH] [--output_dir OUTPUT_DIR]\n",
            "                              [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
            "                              [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
            "                              [--do_predict [DO_PREDICT]] [--eval_strategy {no,steps,epoch}]\n",
            "                              [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
            "                              [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                              [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                              [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                              [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "                              [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                              [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
            "                              [--eval_delay EVAL_DELAY]\n",
            "                              [--torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS]\n",
            "                              [--learning_rate LEARNING_RATE] [--weight_decay WEIGHT_DECAY]\n",
            "                              [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                              [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]\n",
            "                              [--num_train_epochs NUM_TRAIN_EPOCHS] [--max_steps MAX_STEPS]\n",
            "                              [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}]\n",
            "                              [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
            "                              [--warmup_ratio WARMUP_RATIO] [--warmup_steps WARMUP_STEPS]\n",
            "                              [--log_level {detail,debug,info,warning,error,critical,passive}]\n",
            "                              [--log_level_replica {detail,debug,info,warning,error,critical,passive}]\n",
            "                              [--log_on_each_node [LOG_ON_EACH_NODE]] [--no_log_on_each_node]\n",
            "                              [--logging_dir LOGGING_DIR] [--logging_strategy {no,steps,epoch}]\n",
            "                              [--logging_first_step [LOGGING_FIRST_STEP]]\n",
            "                              [--logging_steps LOGGING_STEPS]\n",
            "                              [--logging_nan_inf_filter [LOGGING_NAN_INF_FILTER]]\n",
            "                              [--no_logging_nan_inf_filter]\n",
            "                              [--save_strategy {no,steps,epoch,best}] [--save_steps SAVE_STEPS]\n",
            "                              [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                              [--save_safetensors [SAVE_SAFETENSORS]] [--no_save_safetensors]\n",
            "                              [--save_on_each_node [SAVE_ON_EACH_NODE]]\n",
            "                              [--save_only_model [SAVE_ONLY_MODEL]]\n",
            "                              [--restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]]\n",
            "                              [--no_cuda [NO_CUDA]] [--use_cpu [USE_CPU]]\n",
            "                              [--use_mps_device [USE_MPS_DEVICE]] [--seed SEED]\n",
            "                              [--data_seed DATA_SEED] [--jit_mode_eval [JIT_MODE_EVAL]]\n",
            "                              [--use_ipex [USE_IPEX]] [--bf16 [BF16]] [--fp16 [FP16]]\n",
            "                              [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                              [--half_precision_backend {auto,apex,cpu_amp}]\n",
            "                              [--bf16_full_eval [BF16_FULL_EVAL]]\n",
            "                              [--fp16_full_eval [FP16_FULL_EVAL]] [--tf32 TF32]\n",
            "                              [--local_rank LOCAL_RANK]\n",
            "                              [--ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}]\n",
            "                              [--tpu_num_cores TPU_NUM_CORES]\n",
            "                              [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
            "                              [--debug DEBUG [DEBUG ...]]\n",
            "                              [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
            "                              [--eval_steps EVAL_STEPS]\n",
            "                              [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                              [--dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR]\n",
            "                              [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
            "                              [--disable_tqdm DISABLE_TQDM]\n",
            "                              [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
            "                              [--no_remove_unused_columns]\n",
            "                              [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "                              [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
            "                              [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "                              [--greater_is_better GREATER_IS_BETTER]\n",
            "                              [--ignore_data_skip [IGNORE_DATA_SKIP]] [--fsdp FSDP]\n",
            "                              [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]\n",
            "                              [--fsdp_config FSDP_CONFIG] [--tp_size TP_SIZE]\n",
            "                              [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]\n",
            "                              [--accelerator_config ACCELERATOR_CONFIG] [--deepspeed DEEPSPEED]\n",
            "                              [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
            "                              [--optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}]\n",
            "                              [--optim_args OPTIM_ARGS] [--adafactor [ADAFACTOR]]\n",
            "                              [--group_by_length [GROUP_BY_LENGTH]]\n",
            "                              [--length_column_name LENGTH_COLUMN_NAME] [--report_to REPORT_TO]\n",
            "                              [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
            "                              [--ddp_bucket_cap_mb DDP_BUCKET_CAP_MB]\n",
            "                              [--ddp_broadcast_buffers DDP_BROADCAST_BUFFERS]\n",
            "                              [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
            "                              [--no_dataloader_pin_memory]\n",
            "                              [--dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS]]\n",
            "                              [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
            "                              [--no_skip_memory_metrics]\n",
            "                              [--use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP]]\n",
            "                              [--push_to_hub [PUSH_TO_HUB]]\n",
            "                              [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                              [--hub_model_id HUB_MODEL_ID]\n",
            "                              [--hub_strategy {end,every_save,checkpoint,all_checkpoints}]\n",
            "                              [--hub_token HUB_TOKEN] [--hub_private_repo HUB_PRIVATE_REPO]\n",
            "                              [--hub_always_push [HUB_ALWAYS_PUSH]]\n",
            "                              [--gradient_checkpointing [GRADIENT_CHECKPOINTING]]\n",
            "                              [--gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS]\n",
            "                              [--include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS]]\n",
            "                              [--include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]]\n",
            "                              [--eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES]]\n",
            "                              [--no_eval_do_concat_batches] [--fp16_backend {auto,apex,cpu_amp}]\n",
            "                              [--evaluation_strategy {no,steps,epoch}]\n",
            "                              [--push_to_hub_model_id PUSH_TO_HUB_MODEL_ID]\n",
            "                              [--push_to_hub_organization PUSH_TO_HUB_ORGANIZATION]\n",
            "                              [--push_to_hub_token PUSH_TO_HUB_TOKEN]\n",
            "                              [--mp_parameters MP_PARAMETERS]\n",
            "                              [--auto_find_batch_size [AUTO_FIND_BATCH_SIZE]]\n",
            "                              [--full_determinism [FULL_DETERMINISM]] [--torchdynamo TORCHDYNAMO]\n",
            "                              [--ray_scope RAY_SCOPE] [--ddp_timeout DDP_TIMEOUT]\n",
            "                              [--torch_compile [TORCH_COMPILE]]\n",
            "                              [--torch_compile_backend TORCH_COMPILE_BACKEND]\n",
            "                              [--torch_compile_mode TORCH_COMPILE_MODE]\n",
            "                              [--dispatch_batches DISPATCH_BATCHES]\n",
            "                              [--split_batches SPLIT_BATCHES]\n",
            "                              [--include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND]]\n",
            "                              [--include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]]\n",
            "                              [--neftune_noise_alpha NEFTUNE_NOISE_ALPHA]\n",
            "                              [--optim_target_modules OPTIM_TARGET_MODULES]\n",
            "                              [--batch_eval_metrics [BATCH_EVAL_METRICS]]\n",
            "                              [--eval_on_start [EVAL_ON_START]]\n",
            "                              [--use_liger_kernel [USE_LIGER_KERNEL]]\n",
            "                              [--eval_use_gather_object [EVAL_USE_GATHER_OBJECT]]\n",
            "                              [--average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES]]\n",
            "                              [--do_step_schedule_per_epoch [DO_STEP_SCHEDULE_PER_EPOCH]]\n",
            "                              [--no_do_step_schedule_per_epoch] [--lr_decay LR_DECAY]\n",
            "                              [--weight_duration WEIGHT_DURATION] [--weight_kl WEIGHT_KL]\n",
            "                              [--weight_mel WEIGHT_MEL] [--weight_disc WEIGHT_DISC]\n",
            "                              [--weight_gen WEIGHT_GEN] [--weight_fmaps WEIGHT_FMAPS]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model_name_or_path MODEL_NAME_OR_PATH, --model-name-or-path MODEL_NAME_OR_PATH\n",
            "                        Path to pretrained model or model identifier from huggingface.co/models\n",
            "                        (default: None)\n",
            "  --config_name CONFIG_NAME, --config-name CONFIG_NAME\n",
            "                        Pretrained config name or path if not the same as model_name (default:\n",
            "                        None)\n",
            "  --tokenizer_name TOKENIZER_NAME, --tokenizer-name TOKENIZER_NAME\n",
            "                        Pretrained tokenizer name or path if not the same as model_name (default:\n",
            "                        None)\n",
            "  --feature_extractor_name FEATURE_EXTRACTOR_NAME, --feature-extractor-name FEATURE_EXTRACTOR_NAME\n",
            "                        feature extractor name or path if not the same as model_name (default:\n",
            "                        None)\n",
            "  --cache_dir CACHE_DIR, --cache-dir CACHE_DIR\n",
            "                        Where to store the pretrained models downloaded from huggingface.co\n",
            "                        (default: None)\n",
            "  --use_fast_tokenizer [USE_FAST_TOKENIZER], --use-fast-tokenizer [USE_FAST_TOKENIZER]\n",
            "                        Whether to use one of the fast tokenizer (backed by the tokenizers\n",
            "                        library) or not. (default: True)\n",
            "  --no_use_fast_tokenizer, --no-use-fast-tokenizer\n",
            "                        Whether to use one of the fast tokenizer (backed by the tokenizers\n",
            "                        library) or not. (default: False)\n",
            "  --model_revision MODEL_REVISION, --model-revision MODEL_REVISION\n",
            "                        The specific model version to use (can be a branch name, tag name or\n",
            "                        commit id). (default: main)\n",
            "  --token TOKEN         The token to use as HTTP bearer authorization for remote files. If not\n",
            "                        specified, will use the token generated when running `huggingface-cli\n",
            "                        login` (stored in `~/.huggingface`). (default: None)\n",
            "  --use_auth_token [USE_AUTH_TOKEN], --use-auth-token [USE_AUTH_TOKEN]\n",
            "                        The `use_auth_token` argument is deprecated and will be removed in v4.34.\n",
            "                        Please use `token`. (default: None)\n",
            "  --trust_remote_code [TRUST_REMOTE_CODE], --trust-remote-code [TRUST_REMOTE_CODE]\n",
            "                        Whether or not to allow for custom models defined on the Hub in their own\n",
            "                        modeling files. This optionshould only be set to `True` for repositories\n",
            "                        you trust and in which you have read the code, as it willexecute code\n",
            "                        present on the Hub on your local machine. (default: False)\n",
            "  --override_speaker_embeddings [OVERRIDE_SPEAKER_EMBEDDINGS], --override-speaker-embeddings [OVERRIDE_SPEAKER_EMBEDDINGS]\n",
            "                        If `True` and if `speaker_id_column_name` is specified, it will replace\n",
            "                        current speaker embeddings with a new set of speaker embeddings.If the\n",
            "                        model from the checkpoint didn't have speaker embeddings, it will\n",
            "                        initialize speaker embeddings. (default: False)\n",
            "  --override_vocabulary_embeddings [OVERRIDE_VOCABULARY_EMBEDDINGS], --override-vocabulary-embeddings [OVERRIDE_VOCABULARY_EMBEDDINGS]\n",
            "                        If `True`, it will resize the token embeddings based on the vocabulary\n",
            "                        size of the tokenizer. In other words, use this when you use a different\n",
            "                        tokenizer than the one that was used during pretraining. (default: False)\n",
            "  --project_name PROJECT_NAME, --project-name PROJECT_NAME\n",
            "                        The project name associated to this run. Useful to track your experiment.\n",
            "                        (default: vits_finetuning)\n",
            "  --dataset_name DATASET_NAME, --dataset-name DATASET_NAME\n",
            "                        The name of the dataset to use (via the datasets library). (default: None)\n",
            "  --dataset_config_name DATASET_CONFIG_NAME, --dataset-config-name DATASET_CONFIG_NAME\n",
            "                        The configuration name of the dataset to use (via the datasets library).\n",
            "                        (default: None)\n",
            "  --overwrite_cache [OVERWRITE_CACHE], --overwrite-cache [OVERWRITE_CACHE]\n",
            "                        Overwrite the cached training and evaluation sets (default: False)\n",
            "  --preprocessing_num_workers PREPROCESSING_NUM_WORKERS, --preprocessing-num-workers PREPROCESSING_NUM_WORKERS\n",
            "                        The number of processes to use for the preprocessing. (default: None)\n",
            "  --max_train_samples MAX_TRAIN_SAMPLES, --max-train-samples MAX_TRAIN_SAMPLES\n",
            "                        For debugging purposes or quicker training, truncate the number of\n",
            "                        training examples to this value if set. (default: None)\n",
            "  --max_eval_samples MAX_EVAL_SAMPLES, --max-eval-samples MAX_EVAL_SAMPLES\n",
            "                        For debugging purposes or quicker training, truncate the number of\n",
            "                        evaluation examples to this value if set. (default: None)\n",
            "  --audio_column_name AUDIO_COLUMN_NAME, --audio-column-name AUDIO_COLUMN_NAME\n",
            "                        The name of the dataset column containing the audio data. Defaults to\n",
            "                        'audio' (default: audio)\n",
            "  --text_column_name TEXT_COLUMN_NAME, --text-column-name TEXT_COLUMN_NAME\n",
            "                        The name of the dataset column containing the text data. Defaults to\n",
            "                        'text' (default: text)\n",
            "  --speaker_id_column_name SPEAKER_ID_COLUMN_NAME, --speaker-id-column-name SPEAKER_ID_COLUMN_NAME\n",
            "                        If set, corresponds to the name of the speaker id column containing the\n",
            "                        speaker ids. If `override_speaker_embeddings=False`: it assumes that\n",
            "                        speakers are indexed from 0 to `num_speakers-1`. `num_speakers` and\n",
            "                        `speaker_embedding_size` have to be set in the model config. If\n",
            "                        `override_speaker_embeddings=True`: It will use this column to compute how\n",
            "                        many speakers there are. Defaults to None, i.e it is not used by default.\n",
            "                        (default: None)\n",
            "  --filter_on_speaker_id FILTER_ON_SPEAKER_ID, --filter-on-speaker-id FILTER_ON_SPEAKER_ID\n",
            "                        If `speaker_id_column_name` and `filter_on_speaker_id` are set, will\n",
            "                        filter the dataset to keep a single speaker_id (`filter_on_speaker_id`)\n",
            "                        (default: None)\n",
            "  --max_tokens_length MAX_TOKENS_LENGTH, --max-tokens-length MAX_TOKENS_LENGTH\n",
            "                        Truncate audio files with a transcription that are longer than\n",
            "                        `max_tokens_length` tokens (default: 450)\n",
            "  --max_duration_in_seconds MAX_DURATION_IN_SECONDS, --max-duration-in-seconds MAX_DURATION_IN_SECONDS\n",
            "                        Truncate audio files that are longer than `max_duration_in_seconds`\n",
            "                        seconds to 'max_duration_in_seconds` (default: 20.0)\n",
            "  --min_duration_in_seconds MIN_DURATION_IN_SECONDS, --min-duration-in-seconds MIN_DURATION_IN_SECONDS\n",
            "                        Filter audio files that are shorter than `min_duration_in_seconds` seconds\n",
            "                        (default: 0.0)\n",
            "  --preprocessing_only [PREPROCESSING_ONLY], --preprocessing-only [PREPROCESSING_ONLY]\n",
            "                        Whether to only do data preprocessing and skip training. This is\n",
            "                        especially useful when data preprocessing errors out in distributed\n",
            "                        training due to timeout. In this case, one should run the preprocessing in\n",
            "                        a non-distributed setup with `preprocessing_only=True` so that the cached\n",
            "                        datasets can consequently be loaded in distributed training (default:\n",
            "                        False)\n",
            "  --train_split_name TRAIN_SPLIT_NAME, --train-split-name TRAIN_SPLIT_NAME\n",
            "                        The name of the training data set split to use (via the datasets library).\n",
            "                        Defaults to 'train' (default: train)\n",
            "  --eval_split_name EVAL_SPLIT_NAME, --eval-split-name EVAL_SPLIT_NAME\n",
            "                        The name of the training data set split to use (via the datasets library).\n",
            "                        Defaults to 'train' (default: test)\n",
            "  --do_lower_case [DO_LOWER_CASE], --do-lower-case [DO_LOWER_CASE]\n",
            "                        Whether the input text should be lower cased. (default: False)\n",
            "  --do_normalize [DO_NORMALIZE], --do-normalize [DO_NORMALIZE]\n",
            "                        Whether the input waveform should be normalized. (default: False)\n",
            "  --full_generation_sample_text FULL_GENERATION_SAMPLE_TEXT, --full-generation-sample-text FULL_GENERATION_SAMPLE_TEXT\n",
            "                        Language for multilingual fine-tuning. This argument should be set for\n",
            "                        multilingual fine-tuning only. For English speech recognition, it should\n",
            "                        be set to `None`. (default: This is a test, let's see what comes out of\n",
            "                        this.)\n",
            "  --uroman_path UROMAN_PATH, --uroman-path UROMAN_PATH\n",
            "                        Absolute path to the uroman package. To use if your model requires\n",
            "                        `uroman`.An easy way to check it is to go on your model card and manually\n",
            "                        check `is_uroman` in the `tokenizer_config.json,e.g the French checkpoint\n",
            "                        doesn't need it: https://huggingface.co/facebook/mms-tts-\n",
            "                        fra/blob/main/tokenizer_config.json#L4 (default: None)\n",
            "  --output_dir OUTPUT_DIR, --output-dir OUTPUT_DIR\n",
            "                        The output directory where the model predictions and checkpoints will be\n",
            "                        written. Defaults to 'trainer_output' if not provided. (default: None)\n",
            "  --overwrite_output_dir [OVERWRITE_OUTPUT_DIR], --overwrite-output-dir [OVERWRITE_OUTPUT_DIR]\n",
            "                        Overwrite the content of the output directory. Use this to continue\n",
            "                        training if output_dir points to a checkpoint directory. (default: False)\n",
            "  --do_train [DO_TRAIN], --do-train [DO_TRAIN]\n",
            "                        Whether to run training. (default: False)\n",
            "  --do_eval [DO_EVAL], --do-eval [DO_EVAL]\n",
            "                        Whether to run eval on the dev set. (default: False)\n",
            "  --do_predict [DO_PREDICT], --do-predict [DO_PREDICT]\n",
            "                        Whether to run predictions on the test set. (default: False)\n",
            "  --eval_strategy {no,steps,epoch}, --eval-strategy {no,steps,epoch}\n",
            "                        The evaluation strategy to use. (default: no)\n",
            "  --prediction_loss_only [PREDICTION_LOSS_ONLY], --prediction-loss-only [PREDICTION_LOSS_ONLY]\n",
            "                        When performing evaluation and predictions, only returns the loss.\n",
            "                        (default: False)\n",
            "  --per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE, --per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE\n",
            "                        Batch size per device accelerator core/CPU for training. (default: 8)\n",
            "  --per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE, --per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE\n",
            "                        Batch size per device accelerator core/CPU for evaluation. (default: 8)\n",
            "  --per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE, --per-gpu-train-batch-size PER_GPU_TRAIN_BATCH_SIZE\n",
            "                        Deprecated, the use of `--per_device_train_batch_size` is preferred. Batch\n",
            "                        size per GPU/TPU core/CPU for training. (default: None)\n",
            "  --per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE, --per-gpu-eval-batch-size PER_GPU_EVAL_BATCH_SIZE\n",
            "                        Deprecated, the use of `--per_device_eval_batch_size` is preferred. Batch\n",
            "                        size per GPU/TPU core/CPU for evaluation. (default: None)\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS, --gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS\n",
            "                        Number of updates steps to accumulate before performing a backward/update\n",
            "                        pass. (default: 1)\n",
            "  --eval_accumulation_steps EVAL_ACCUMULATION_STEPS, --eval-accumulation-steps EVAL_ACCUMULATION_STEPS\n",
            "                        Number of predictions steps to accumulate before moving the tensors to the\n",
            "                        CPU. (default: None)\n",
            "  --eval_delay EVAL_DELAY, --eval-delay EVAL_DELAY\n",
            "                        Number of epochs or steps to wait for before the first evaluation can be\n",
            "                        performed, depending on the eval_strategy. (default: 0)\n",
            "  --torch_empty_cache_steps TORCH_EMPTY_CACHE_STEPS, --torch-empty-cache-steps TORCH_EMPTY_CACHE_STEPS\n",
            "                        Number of steps to wait before calling `torch.<device>.empty_cache()`.This\n",
            "                        can help avoid CUDA out-of-memory errors by lowering peak VRAM usage at a\n",
            "                        cost of about [10{'option_strings': ['--torch_empty_cache_steps', '--\n",
            "                        torch-empty-cache-steps'], 'dest': 'torch_empty_cache_steps', 'nargs':\n",
            "                        None, 'const': None, 'default': None, 'type': 'int', 'choices': None,\n",
            "                        'required': False, 'help': 'Number of steps to wait before calling\n",
            "                        `torch.<device>.empty_cache()`.This can help avoid CUDA out-of-memory\n",
            "                        errors by lowering peak VRAM usage at a cost of about [10% slower\n",
            "                        performance](https://github.com/huggingface/transformers/issues/31372).If\n",
            "                        left unset or set to None, cache will not be emptied.', 'metavar': None,\n",
            "                        'container': <argparse._ArgumentGroup object at 0x7ec04943b410>, 'prog':\n",
            "                        'run_vits_finetuning.py'}lower\n",
            "                        performance](https://github.com/huggingface/transformers/issues/31372).If\n",
            "                        left unset or set to None, cache will not be emptied. (default: None)\n",
            "  --learning_rate LEARNING_RATE, --learning-rate LEARNING_RATE\n",
            "                        The initial learning rate for AdamW. (default: 5e-05)\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay for AdamW if we apply some. (default: 0.0)\n",
            "  --adam_beta1 ADAM_BETA1, --adam-beta1 ADAM_BETA1\n",
            "                        Beta1 for AdamW optimizer (default: 0.9)\n",
            "  --adam_beta2 ADAM_BETA2, --adam-beta2 ADAM_BETA2\n",
            "                        Beta2 for AdamW optimizer (default: 0.999)\n",
            "  --adam_epsilon ADAM_EPSILON, --adam-epsilon ADAM_EPSILON\n",
            "                        Epsilon for AdamW optimizer. (default: 1e-08)\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm. (default: 1.0)\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS, --num-train-epochs NUM_TRAIN_EPOCHS\n",
            "                        Total number of training epochs to perform. (default: 3.0)\n",
            "  --max_steps MAX_STEPS, --max-steps MAX_STEPS\n",
            "                        If > 0: set total number of training steps to perform. Override\n",
            "                        num_train_epochs. (default: -1)\n",
            "  --lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}, --lr-scheduler-type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}\n",
            "                        The scheduler type to use. (default: linear)\n",
            "  --lr_scheduler_kwargs LR_SCHEDULER_KWARGS, --lr-scheduler-kwargs LR_SCHEDULER_KWARGS\n",
            "                        Extra parameters for the lr_scheduler such as {'num_cycles': 1} for the\n",
            "                        cosine with hard restarts. (default: {})\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Linear warmup over warmup_ratio fraction of total steps. (default: 0.0)\n",
            "  --warmup_steps WARMUP_STEPS, --warmup-steps WARMUP_STEPS\n",
            "                        Linear warmup over warmup_steps. (default: 0)\n",
            "  --log_level {detail,debug,info,warning,error,critical,passive}, --log-level {detail,debug,info,warning,error,critical,passive}\n",
            "                        Logger log level to use on the main node. Possible choices are the log\n",
            "                        levels as strings: 'debug', 'info', 'warning', 'error' and 'critical',\n",
            "                        plus a 'passive' level which doesn't set anything and lets the application\n",
            "                        set the level. Defaults to 'passive'. (default: passive)\n",
            "  --log_level_replica {detail,debug,info,warning,error,critical,passive}, --log-level-replica {detail,debug,info,warning,error,critical,passive}\n",
            "                        Logger log level to use on replica nodes. Same choices and defaults as\n",
            "                        ``log_level`` (default: warning)\n",
            "  --log_on_each_node [LOG_ON_EACH_NODE], --log-on-each-node [LOG_ON_EACH_NODE]\n",
            "                        When doing a multinode distributed training, whether to log once per node\n",
            "                        or just once on the main node. (default: True)\n",
            "  --no_log_on_each_node, --no-log-on-each-node\n",
            "                        When doing a multinode distributed training, whether to log once per node\n",
            "                        or just once on the main node. (default: False)\n",
            "  --logging_dir LOGGING_DIR, --logging-dir LOGGING_DIR\n",
            "                        Tensorboard log dir. (default: None)\n",
            "  --logging_strategy {no,steps,epoch}, --logging-strategy {no,steps,epoch}\n",
            "                        The logging strategy to use. (default: steps)\n",
            "  --logging_first_step [LOGGING_FIRST_STEP], --logging-first-step [LOGGING_FIRST_STEP]\n",
            "                        Log the first global_step (default: False)\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Log every X updates steps. Should be an integer or a float in range\n",
            "                        `[0,1)`. If smaller than 1, will be interpreted as ratio of total training\n",
            "                        steps. (default: 500)\n",
            "  --logging_nan_inf_filter [LOGGING_NAN_INF_FILTER], --logging-nan-inf-filter [LOGGING_NAN_INF_FILTER]\n",
            "                        Filter nan and inf losses for logging. (default: True)\n",
            "  --no_logging_nan_inf_filter, --no-logging-nan-inf-filter\n",
            "                        Filter nan and inf losses for logging. (default: False)\n",
            "  --save_strategy {no,steps,epoch,best}, --save-strategy {no,steps,epoch,best}\n",
            "                        The checkpoint save strategy to use. (default: steps)\n",
            "  --save_steps SAVE_STEPS, --save-steps SAVE_STEPS\n",
            "                        Save checkpoint every X updates steps. Should be an integer or a float in\n",
            "                        range `[0,1)`. If smaller than 1, will be interpreted as ratio of total\n",
            "                        training steps. (default: 500)\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        If a value is passed, will limit the total amount of checkpoints. Deletes\n",
            "                        the older checkpoints in `output_dir`. When `load_best_model_at_end` is\n",
            "                        enabled, the 'best' checkpoint according to `metric_for_best_model` will\n",
            "                        always be retained in addition to the most recent ones. For example, for\n",
            "                        `save_total_limit=5` and `load_best_model_at_end=True`, the four last\n",
            "                        checkpoints will always be retained alongside the best model. When\n",
            "                        `save_total_limit=1` and `load_best_model_at_end=True`, it is possible\n",
            "                        that two checkpoints are saved: the last one and the best one (if they are\n",
            "                        different). Default is unlimited checkpoints (default: None)\n",
            "  --save_safetensors [SAVE_SAFETENSORS], --save-safetensors [SAVE_SAFETENSORS]\n",
            "                        Use safetensors saving and loading for state dicts instead of default\n",
            "                        torch.load and torch.save. (default: True)\n",
            "  --no_save_safetensors, --no-save-safetensors\n",
            "                        Use safetensors saving and loading for state dicts instead of default\n",
            "                        torch.load and torch.save. (default: False)\n",
            "  --save_on_each_node [SAVE_ON_EACH_NODE], --save-on-each-node [SAVE_ON_EACH_NODE]\n",
            "                        When doing multi-node distributed training, whether to save models and\n",
            "                        checkpoints on each node, or only on the main one (default: False)\n",
            "  --save_only_model [SAVE_ONLY_MODEL], --save-only-model [SAVE_ONLY_MODEL]\n",
            "                        When checkpointing, whether to only save the model, or also the optimizer,\n",
            "                        scheduler & rng state.Note that when this is true, you won't be able to\n",
            "                        resume training from checkpoint.This enables you to save storage by not\n",
            "                        storing the optimizer, scheduler & rng state.You can only load the model\n",
            "                        using from_pretrained with this option set to True. (default: False)\n",
            "  --restore_callback_states_from_checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT], --restore-callback-states-from-checkpoint [RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]\n",
            "                        Whether to restore the callback states from the checkpoint. If `True`,\n",
            "                        will override callbacks passed to the `Trainer` if they exist in the\n",
            "                        checkpoint. (default: False)\n",
            "  --no_cuda [NO_CUDA], --no-cuda [NO_CUDA]\n",
            "                        This argument is deprecated. It will be removed in version 5.0 of 🤗\n",
            "                        Transformers. (default: False)\n",
            "  --use_cpu [USE_CPU], --use-cpu [USE_CPU]\n",
            "                        Whether or not to use cpu. If left to False, we will use the available\n",
            "                        torch device/backend (cuda/mps/xpu/hpu etc.) (default: False)\n",
            "  --use_mps_device [USE_MPS_DEVICE], --use-mps-device [USE_MPS_DEVICE]\n",
            "                        This argument is deprecated. `mps` device will be used if available\n",
            "                        similar to `cuda` device. It will be removed in version 5.0 of 🤗\n",
            "                        Transformers (default: False)\n",
            "  --seed SEED           Random seed that will be set at the beginning of training. (default: 42)\n",
            "  --data_seed DATA_SEED, --data-seed DATA_SEED\n",
            "                        Random seed to be used with data samplers. (default: None)\n",
            "  --jit_mode_eval [JIT_MODE_EVAL], --jit-mode-eval [JIT_MODE_EVAL]\n",
            "                        Whether or not to use PyTorch jit trace for inference (default: False)\n",
            "  --use_ipex [USE_IPEX], --use-ipex [USE_IPEX]\n",
            "                        Use Intel extension for PyTorch when it is available, installation:\n",
            "                        'https://github.com/intel/intel-extension-for-pytorch' (default: False)\n",
            "  --bf16 [BF16]         Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere\n",
            "                        or higher NVIDIA architecture or using CPU (use_cpu) or Ascend NPU. This\n",
            "                        is an experimental API and it may change. (default: False)\n",
            "  --fp16 [FP16]         Whether to use fp16 (mixed) precision instead of 32-bit (default: False)\n",
            "  --fp16_opt_level FP16_OPT_LEVEL, --fp16-opt-level FP16_OPT_LEVEL\n",
            "                        For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and\n",
            "                        'O3']. See details at https://nvidia.github.io/apex/amp.html (default: O1)\n",
            "  --half_precision_backend {auto,apex,cpu_amp}, --half-precision-backend {auto,apex,cpu_amp}\n",
            "                        The backend to be used for half precision. (default: auto)\n",
            "  --bf16_full_eval [BF16_FULL_EVAL], --bf16-full-eval [BF16_FULL_EVAL]\n",
            "                        Whether to use full bfloat16 evaluation instead of 32-bit. This is an\n",
            "                        experimental API and it may change. (default: False)\n",
            "  --fp16_full_eval [FP16_FULL_EVAL], --fp16-full-eval [FP16_FULL_EVAL]\n",
            "                        Whether to use full float16 evaluation instead of 32-bit (default: False)\n",
            "  --tf32 TF32           Whether to enable tf32 mode, available in Ampere and newer GPU\n",
            "                        architectures. This is an experimental API and it may change. (default:\n",
            "                        None)\n",
            "  --local_rank LOCAL_RANK, --local-rank LOCAL_RANK\n",
            "                        For distributed training: local_rank (default: -1)\n",
            "  --ddp_backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}, --ddp-backend {nccl,gloo,mpi,ccl,hccl,cncl,mccl}\n",
            "                        The backend to be used for distributed training (default: None)\n",
            "  --tpu_num_cores TPU_NUM_CORES, --tpu-num-cores TPU_NUM_CORES\n",
            "                        TPU: Number of TPU cores (automatically passed by launcher script)\n",
            "                        (default: None)\n",
            "  --tpu_metrics_debug [TPU_METRICS_DEBUG], --tpu-metrics-debug [TPU_METRICS_DEBUG]\n",
            "                        Deprecated, the use of `--debug tpu_metrics_debug` is preferred. TPU:\n",
            "                        Whether to print debug metrics (default: False)\n",
            "  --debug DEBUG [DEBUG ...]\n",
            "                        Whether or not to enable debug mode. Current options: `underflow_overflow`\n",
            "                        (Detect underflow and overflow in activations and weights),\n",
            "                        `tpu_metrics_debug` (print debug metrics on TPU). (default: None)\n",
            "  --dataloader_drop_last [DATALOADER_DROP_LAST], --dataloader-drop-last [DATALOADER_DROP_LAST]\n",
            "                        Drop the last incomplete batch if it is not divisible by the batch size.\n",
            "                        (default: False)\n",
            "  --eval_steps EVAL_STEPS, --eval-steps EVAL_STEPS\n",
            "                        Run an evaluation every X steps. Should be an integer or a float in range\n",
            "                        `[0,1)`. If smaller than 1, will be interpreted as ratio of total training\n",
            "                        steps. (default: None)\n",
            "  --dataloader_num_workers DATALOADER_NUM_WORKERS, --dataloader-num-workers DATALOADER_NUM_WORKERS\n",
            "                        Number of subprocesses to use for data loading (PyTorch only). 0 means\n",
            "                        that the data will be loaded in the main process. (default: 0)\n",
            "  --dataloader_prefetch_factor DATALOADER_PREFETCH_FACTOR, --dataloader-prefetch-factor DATALOADER_PREFETCH_FACTOR\n",
            "                        Number of batches loaded in advance by each worker. 2 means there will be\n",
            "                        a total of 2 * num_workers batches prefetched across all workers. Default\n",
            "                        is 2 for PyTorch < 2.0.0 and otherwise None. (default: None)\n",
            "  --past_index PAST_INDEX, --past-index PAST_INDEX\n",
            "                        If >=0, uses the corresponding part of the output as the past state for\n",
            "                        next step. (default: -1)\n",
            "  --run_name RUN_NAME, --run-name RUN_NAME\n",
            "                        An optional descriptor for the run. Notably used for wandb, mlflow comet\n",
            "                        and swanlab logging. (default: None)\n",
            "  --disable_tqdm DISABLE_TQDM, --disable-tqdm DISABLE_TQDM\n",
            "                        Whether or not to disable the tqdm progress bars. (default: None)\n",
            "  --remove_unused_columns [REMOVE_UNUSED_COLUMNS], --remove-unused-columns [REMOVE_UNUSED_COLUMNS]\n",
            "                        Remove columns not required by the model when using an nlp.Dataset.\n",
            "                        (default: True)\n",
            "  --no_remove_unused_columns, --no-remove-unused-columns\n",
            "                        Remove columns not required by the model when using an nlp.Dataset.\n",
            "                        (default: False)\n",
            "  --label_names LABEL_NAMES [LABEL_NAMES ...], --label-names LABEL_NAMES [LABEL_NAMES ...]\n",
            "                        The list of keys in your dictionary of inputs that correspond to the\n",
            "                        labels. (default: None)\n",
            "  --load_best_model_at_end [LOAD_BEST_MODEL_AT_END], --load-best-model-at-end [LOAD_BEST_MODEL_AT_END]\n",
            "                        Whether or not to load the best model found during training at the end of\n",
            "                        training. When this option is enabled, the best checkpoint will always be\n",
            "                        saved. See `save_total_limit` for more. (default: False)\n",
            "  --metric_for_best_model METRIC_FOR_BEST_MODEL, --metric-for-best-model METRIC_FOR_BEST_MODEL\n",
            "                        The metric to use to compare two different models. (default: None)\n",
            "  --greater_is_better GREATER_IS_BETTER, --greater-is-better GREATER_IS_BETTER\n",
            "                        Whether the `metric_for_best_model` should be maximized or not. (default:\n",
            "                        None)\n",
            "  --ignore_data_skip [IGNORE_DATA_SKIP], --ignore-data-skip [IGNORE_DATA_SKIP]\n",
            "                        When resuming training, whether or not to skip the first epochs and\n",
            "                        batches to get to the same training data. (default: False)\n",
            "  --fsdp FSDP           Whether or not to use PyTorch Fully Sharded Data Parallel (FSDP) training\n",
            "                        (in distributed training only). The base option should be `full_shard`,\n",
            "                        `shard_grad_op` or `no_shard` and you can add CPU-offload to `full_shard`\n",
            "                        or `shard_grad_op` like this: full_shard offload` or `shard_grad_op\n",
            "                        offload`. You can add auto-wrap to `full_shard` or `shard_grad_op` with\n",
            "                        the same syntax: full_shard auto_wrap` or `shard_grad_op auto_wrap`.\n",
            "                        (default: )\n",
            "  --fsdp_min_num_params FSDP_MIN_NUM_PARAMS, --fsdp-min-num-params FSDP_MIN_NUM_PARAMS\n",
            "                        This parameter is deprecated. FSDP's minimum number of parameters for\n",
            "                        Default Auto Wrapping. (useful only when `fsdp` field is passed).\n",
            "                        (default: 0)\n",
            "  --fsdp_config FSDP_CONFIG, --fsdp-config FSDP_CONFIG\n",
            "                        Config to be used with FSDP (Pytorch Fully Sharded Data Parallel). The\n",
            "                        value is either a fsdp json config file (e.g., `fsdp_config.json`) or an\n",
            "                        already loaded json file as `dict`. (default: None)\n",
            "  --tp_size TP_SIZE, --tp-size TP_SIZE\n",
            "                        Use tp_size to enable pytorch tensor parallelism.Tensor parallelism\n",
            "                        support is only available to models having `base_tp_plan` in their\n",
            "                        respective config classes.Set a value greater than 1 to activate TP.The\n",
            "                        same is used to prepare device mesh internally.Requires accelerate>1.3.0.\n",
            "                        (default: 0)\n",
            "  --fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP, --fsdp-transformer-layer-cls-to-wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP\n",
            "                        This parameter is deprecated. Transformer layer class name (case-\n",
            "                        sensitive) to wrap, e.g, `BertLayer`, `GPTJBlock`, `T5Block` .... (useful\n",
            "                        only when `fsdp` flag is passed). (default: None)\n",
            "  --accelerator_config ACCELERATOR_CONFIG, --accelerator-config ACCELERATOR_CONFIG\n",
            "                        Config to be used with the internal Accelerator object initialization. The\n",
            "                        value is either a accelerator json config file (e.g.,\n",
            "                        `accelerator_config.json`) or an already loaded json file as `dict`.\n",
            "                        (default: None)\n",
            "  --deepspeed DEEPSPEED\n",
            "                        Enable deepspeed and pass the path to deepspeed json config file (e.g.\n",
            "                        `ds_config.json`) or an already loaded json file as a dict (default: None)\n",
            "  --label_smoothing_factor LABEL_SMOOTHING_FACTOR, --label-smoothing-factor LABEL_SMOOTHING_FACTOR\n",
            "                        The label smoothing epsilon to apply (zero means no label smoothing).\n",
            "                        (default: 0.0)\n",
            "  --optim {adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,adamw_torch_4bit,adamw_torch_8bit,ademamix,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,ademamix_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_ademamix_32bit,paged_ademamix_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo,grokadamw,schedule_free_radam,schedule_free_adamw,schedule_free_sgd,apollo_adamw,apollo_adamw_layerwise}\n",
            "                        The optimizer to use. (default: adamw_torch)\n",
            "  --optim_args OPTIM_ARGS, --optim-args OPTIM_ARGS\n",
            "                        Optional arguments to supply to optimizer. (default: None)\n",
            "  --adafactor [ADAFACTOR]\n",
            "                        Whether or not to replace AdamW by Adafactor. (default: False)\n",
            "  --group_by_length [GROUP_BY_LENGTH], --group-by-length [GROUP_BY_LENGTH]\n",
            "                        Whether or not to group samples of roughly the same length together when\n",
            "                        batching. (default: False)\n",
            "  --length_column_name LENGTH_COLUMN_NAME, --length-column-name LENGTH_COLUMN_NAME\n",
            "                        Column name with precomputed lengths to use when grouping by length.\n",
            "                        (default: length)\n",
            "  --report_to REPORT_TO, --report-to REPORT_TO\n",
            "                        The list of integrations to report the results and logs to. (default:\n",
            "                        None)\n",
            "  --ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS, --ddp-find-unused-parameters DDP_FIND_UNUSED_PARAMETERS\n",
            "                        When using distributed training, the value of the flag\n",
            "                        `find_unused_parameters` passed to `DistributedDataParallel`. (default:\n",
            "                        None)\n",
            "  --ddp_bucket_cap_mb DDP_BUCKET_CAP_MB, --ddp-bucket-cap-mb DDP_BUCKET_CAP_MB\n",
            "                        When using distributed training, the value of the flag `bucket_cap_mb`\n",
            "                        passed to `DistributedDataParallel`. (default: None)\n",
            "  --ddp_broadcast_buffers DDP_BROADCAST_BUFFERS, --ddp-broadcast-buffers DDP_BROADCAST_BUFFERS\n",
            "                        When using distributed training, the value of the flag `broadcast_buffers`\n",
            "                        passed to `DistributedDataParallel`. (default: None)\n",
            "  --dataloader_pin_memory [DATALOADER_PIN_MEMORY], --dataloader-pin-memory [DATALOADER_PIN_MEMORY]\n",
            "                        Whether or not to pin memory for DataLoader. (default: True)\n",
            "  --no_dataloader_pin_memory, --no-dataloader-pin-memory\n",
            "                        Whether or not to pin memory for DataLoader. (default: False)\n",
            "  --dataloader_persistent_workers [DATALOADER_PERSISTENT_WORKERS], --dataloader-persistent-workers [DATALOADER_PERSISTENT_WORKERS]\n",
            "                        If True, the data loader will not shut down the worker processes after a\n",
            "                        dataset has been consumed once. This allows to maintain the workers\n",
            "                        Dataset instances alive. Can potentially speed up training, but will\n",
            "                        increase RAM usage. (default: False)\n",
            "  --skip_memory_metrics [SKIP_MEMORY_METRICS], --skip-memory-metrics [SKIP_MEMORY_METRICS]\n",
            "                        Whether or not to skip adding of memory profiler reports to metrics.\n",
            "                        (default: True)\n",
            "  --no_skip_memory_metrics, --no-skip-memory-metrics\n",
            "                        Whether or not to skip adding of memory profiler reports to metrics.\n",
            "                        (default: False)\n",
            "  --use_legacy_prediction_loop [USE_LEGACY_PREDICTION_LOOP], --use-legacy-prediction-loop [USE_LEGACY_PREDICTION_LOOP]\n",
            "                        Whether or not to use the legacy prediction_loop in the Trainer. (default:\n",
            "                        False)\n",
            "  --push_to_hub [PUSH_TO_HUB], --push-to-hub [PUSH_TO_HUB]\n",
            "                        Whether or not to upload the trained model to the model hub after\n",
            "                        training. (default: False)\n",
            "  --resume_from_checkpoint RESUME_FROM_CHECKPOINT, --resume-from-checkpoint RESUME_FROM_CHECKPOINT\n",
            "                        The path to a folder with a valid checkpoint for your model. (default:\n",
            "                        None)\n",
            "  --hub_model_id HUB_MODEL_ID, --hub-model-id HUB_MODEL_ID\n",
            "                        The name of the repository to keep in sync with the local `output_dir`.\n",
            "                        (default: None)\n",
            "  --hub_strategy {end,every_save,checkpoint,all_checkpoints}, --hub-strategy {end,every_save,checkpoint,all_checkpoints}\n",
            "                        The hub strategy to use when `--push_to_hub` is activated. (default:\n",
            "                        every_save)\n",
            "  --hub_token HUB_TOKEN, --hub-token HUB_TOKEN\n",
            "                        The token to use to push to the Model Hub. (default: None)\n",
            "  --hub_private_repo HUB_PRIVATE_REPO, --hub-private-repo HUB_PRIVATE_REPO\n",
            "                        Whether to make the repo private. If `None` (default), the repo will be\n",
            "                        public unless the organization's default is private. This value is ignored\n",
            "                        if the repo already exists. (default: None)\n",
            "  --hub_always_push [HUB_ALWAYS_PUSH], --hub-always-push [HUB_ALWAYS_PUSH]\n",
            "                        Unless `True`, the Trainer will skip pushes if the previous one wasn't\n",
            "                        finished yet. (default: False)\n",
            "  --gradient_checkpointing [GRADIENT_CHECKPOINTING], --gradient-checkpointing [GRADIENT_CHECKPOINTING]\n",
            "                        If True, use gradient checkpointing to save memory at the expense of\n",
            "                        slower backward pass. (default: False)\n",
            "  --gradient_checkpointing_kwargs GRADIENT_CHECKPOINTING_KWARGS, --gradient-checkpointing-kwargs GRADIENT_CHECKPOINTING_KWARGS\n",
            "                        Gradient checkpointing key word arguments such as `use_reentrant`. Will be\n",
            "                        passed to `torch.utils.checkpoint.checkpoint` through\n",
            "                        `model.gradient_checkpointing_enable`. (default: None)\n",
            "  --include_inputs_for_metrics [INCLUDE_INPUTS_FOR_METRICS], --include-inputs-for-metrics [INCLUDE_INPUTS_FOR_METRICS]\n",
            "                        This argument is deprecated and will be removed in version 5 of 🤗\n",
            "                        Transformers. Use `include_for_metrics` instead. (default: False)\n",
            "  --include_for_metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...], --include-for-metrics INCLUDE_FOR_METRICS [INCLUDE_FOR_METRICS ...]\n",
            "                        List of strings to specify additional data to include in the\n",
            "                        `compute_metrics` function.Options: 'inputs', 'loss'. (default: [])\n",
            "  --eval_do_concat_batches [EVAL_DO_CONCAT_BATCHES], --eval-do-concat-batches [EVAL_DO_CONCAT_BATCHES]\n",
            "                        Whether to recursively concat inputs/losses/labels/predictions across\n",
            "                        batches. If `False`, will instead store them as lists, with each batch\n",
            "                        kept separate. (default: True)\n",
            "  --no_eval_do_concat_batches, --no-eval-do-concat-batches\n",
            "                        Whether to recursively concat inputs/losses/labels/predictions across\n",
            "                        batches. If `False`, will instead store them as lists, with each batch\n",
            "                        kept separate. (default: False)\n",
            "  --fp16_backend {auto,apex,cpu_amp}, --fp16-backend {auto,apex,cpu_amp}\n",
            "                        Deprecated. Use half_precision_backend instead (default: auto)\n",
            "  --evaluation_strategy {no,steps,epoch}, --evaluation-strategy {no,steps,epoch}\n",
            "                        Deprecated. Use `eval_strategy` instead (default: None)\n",
            "  --push_to_hub_model_id PUSH_TO_HUB_MODEL_ID, --push-to-hub-model-id PUSH_TO_HUB_MODEL_ID\n",
            "                        The name of the repository to which push the `Trainer`. (default: None)\n",
            "  --push_to_hub_organization PUSH_TO_HUB_ORGANIZATION, --push-to-hub-organization PUSH_TO_HUB_ORGANIZATION\n",
            "                        The name of the organization in with to which push the `Trainer`.\n",
            "                        (default: None)\n",
            "  --push_to_hub_token PUSH_TO_HUB_TOKEN, --push-to-hub-token PUSH_TO_HUB_TOKEN\n",
            "                        The token to use to push to the Model Hub. (default: None)\n",
            "  --mp_parameters MP_PARAMETERS, --mp-parameters MP_PARAMETERS\n",
            "                        Used by the SageMaker launcher to send mp-specific args. Ignored in\n",
            "                        Trainer (default: )\n",
            "  --auto_find_batch_size [AUTO_FIND_BATCH_SIZE], --auto-find-batch-size [AUTO_FIND_BATCH_SIZE]\n",
            "                        Whether to automatically decrease the batch size in half and rerun the\n",
            "                        training loop again each time a CUDA Out-of-Memory was reached (default:\n",
            "                        False)\n",
            "  --full_determinism [FULL_DETERMINISM], --full-determinism [FULL_DETERMINISM]\n",
            "                        Whether to call enable_full_determinism instead of set_seed for\n",
            "                        reproducibility in distributed training. Important: this will negatively\n",
            "                        impact the performance, so only use it for debugging. (default: False)\n",
            "  --torchdynamo TORCHDYNAMO\n",
            "                        This argument is deprecated, use `--torch_compile_backend` instead.\n",
            "                        (default: None)\n",
            "  --ray_scope RAY_SCOPE, --ray-scope RAY_SCOPE\n",
            "                        The scope to use when doing hyperparameter search with Ray. By default,\n",
            "                        `\"last\"` will be used. Ray will then use the last checkpoint of all\n",
            "                        trials, compare those, and select the best one. However, other options are\n",
            "                        also available. See the Ray documentation (https://docs.ray.io/en/latest/t\n",
            "                        une/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial) for\n",
            "                        more options. (default: last)\n",
            "  --ddp_timeout DDP_TIMEOUT, --ddp-timeout DDP_TIMEOUT\n",
            "                        Overrides the default timeout for distributed training (value should be\n",
            "                        given in seconds). (default: 1800)\n",
            "  --torch_compile [TORCH_COMPILE], --torch-compile [TORCH_COMPILE]\n",
            "                        If set to `True`, the model will be wrapped in `torch.compile`. (default:\n",
            "                        False)\n",
            "  --torch_compile_backend TORCH_COMPILE_BACKEND, --torch-compile-backend TORCH_COMPILE_BACKEND\n",
            "                        Which backend to use with `torch.compile`, passing one will trigger a\n",
            "                        model compilation. (default: None)\n",
            "  --torch_compile_mode TORCH_COMPILE_MODE, --torch-compile-mode TORCH_COMPILE_MODE\n",
            "                        Which mode to use with `torch.compile`, passing one will trigger a model\n",
            "                        compilation. (default: None)\n",
            "  --dispatch_batches DISPATCH_BATCHES, --dispatch-batches DISPATCH_BATCHES\n",
            "                        Deprecated. Pass {'dispatch_batches':VALUE} to `accelerator_config`.\n",
            "                        (default: None)\n",
            "  --split_batches SPLIT_BATCHES, --split-batches SPLIT_BATCHES\n",
            "                        Deprecated. Pass {'split_batches':True} to `accelerator_config`. (default:\n",
            "                        None)\n",
            "  --include_tokens_per_second [INCLUDE_TOKENS_PER_SECOND], --include-tokens-per-second [INCLUDE_TOKENS_PER_SECOND]\n",
            "                        If set to `True`, the speed metrics will include `tgs` (tokens per second\n",
            "                        per device). (default: False)\n",
            "  --include_num_input_tokens_seen [INCLUDE_NUM_INPUT_TOKENS_SEEN], --include-num-input-tokens-seen [INCLUDE_NUM_INPUT_TOKENS_SEEN]\n",
            "                        If set to `True`, will track the number of input tokens seen throughout\n",
            "                        training. (May be slower in distributed training) (default: False)\n",
            "  --neftune_noise_alpha NEFTUNE_NOISE_ALPHA, --neftune-noise-alpha NEFTUNE_NOISE_ALPHA\n",
            "                        Activates neftune noise embeddings into the model. NEFTune has been proven\n",
            "                        to drastically improve model performances for instruction fine-tuning.\n",
            "                        Check out the original paper here: https://arxiv.org/abs/2310.05914 and\n",
            "                        the original code here: https://github.com/neelsjain/NEFTune. Only\n",
            "                        supported for `PreTrainedModel` and `PeftModel` classes. (default: None)\n",
            "  --optim_target_modules OPTIM_TARGET_MODULES, --optim-target-modules OPTIM_TARGET_MODULES\n",
            "                        Target modules for the optimizer defined in the `optim` argument. Only\n",
            "                        used for the GaLore optimizer at the moment. (default: None)\n",
            "  --batch_eval_metrics [BATCH_EVAL_METRICS], --batch-eval-metrics [BATCH_EVAL_METRICS]\n",
            "                        Break eval metrics calculation into batches to save memory. (default:\n",
            "                        False)\n",
            "  --eval_on_start [EVAL_ON_START], --eval-on-start [EVAL_ON_START]\n",
            "                        Whether to run through the entire `evaluation` step at the very beginning\n",
            "                        of training as a sanity check. (default: False)\n",
            "  --use_liger_kernel [USE_LIGER_KERNEL], --use-liger-kernel [USE_LIGER_KERNEL]\n",
            "                        Whether or not to enable the Liger Kernel for model training. (default:\n",
            "                        False)\n",
            "  --eval_use_gather_object [EVAL_USE_GATHER_OBJECT], --eval-use-gather-object [EVAL_USE_GATHER_OBJECT]\n",
            "                        Whether to run recursively gather object in a nested list/tuple/dictionary\n",
            "                        of objects from all devices. (default: False)\n",
            "  --average_tokens_across_devices [AVERAGE_TOKENS_ACROSS_DEVICES], --average-tokens-across-devices [AVERAGE_TOKENS_ACROSS_DEVICES]\n",
            "                        Whether or not to average tokens across devices. If enabled, will use\n",
            "                        all_reduce to synchronize num_tokens_in_batch for precise loss\n",
            "                        calculation. Reference:\n",
            "                        https://github.com/huggingface/transformers/issues/34242 (default: False)\n",
            "  --do_step_schedule_per_epoch [DO_STEP_SCHEDULE_PER_EPOCH], --do-step-schedule-per-epoch [DO_STEP_SCHEDULE_PER_EPOCH]\n",
            "                        Whether or not to perform scheduler steps per epoch or per steps. If\n",
            "                        `True`, the scheduler will be `ExponentialLR` parametrized with\n",
            "                        `lr_decay`. (default: True)\n",
            "  --no_do_step_schedule_per_epoch, --no-do-step-schedule-per-epoch\n",
            "                        Whether or not to perform scheduler steps per epoch or per steps. If\n",
            "                        `True`, the scheduler will be `ExponentialLR` parametrized with\n",
            "                        `lr_decay`. (default: False)\n",
            "  --lr_decay LR_DECAY, --lr-decay LR_DECAY\n",
            "                        Learning rate decay, used with `ExponentialLR` when\n",
            "                        `do_step_schedule_per_epoch`. (default: 0.999875)\n",
            "  --weight_duration WEIGHT_DURATION, --weight-duration WEIGHT_DURATION\n",
            "                        Duration loss weight. (default: 1.0)\n",
            "  --weight_kl WEIGHT_KL, --weight-kl WEIGHT_KL\n",
            "                        KL loss weight. (default: 1.5)\n",
            "  --weight_mel WEIGHT_MEL, --weight-mel WEIGHT_MEL\n",
            "                        Mel-spectrogram loss weight (default: 35.0)\n",
            "  --weight_disc WEIGHT_DISC, --weight-disc WEIGHT_DISC\n",
            "                        Discriminator loss weight (default: 3.0)\n",
            "  --weight_gen WEIGHT_GEN, --weight-gen WEIGHT_GEN\n",
            "                        Generator loss weight (default: 1.0)\n",
            "  --weight_fmaps WEIGHT_FMAPS, --weight-fmaps WEIGHT_FMAPS\n",
            "                        Feature map loss weight (default: 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch finetune_vie_own.json"
      ],
      "metadata": {
        "id": "UawYkkyewhbY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_vits_finetuning.py finetune_vie_own.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqfKbFcizpde",
        "outputId": "fab8e20c-3ce6-45cf-9eab-4d4dabb10c01"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `0`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-04-03 18:02:21.597219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743703341.631424    7823 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743703341.642047    7823 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-03 18:02:21.679979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "04/03/2025 18:02:28 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: False, 16-bits training: True\n",
            "04/03/2025 18:02:28 - INFO - __main__ - Training/evaluation parameters VITSTrainingArguments(\n",
            "_n_gpu=0,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.8,\n",
            "adam_beta2=0.99,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_step_schedule_per_epoch=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=mms-tts-vie-own,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/tmp/vits_finetuned/runs/Apr03_18-02-26_b368657c305a,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_decay=0.999875,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=200,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/tmp/vits_finetuned,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/tmp/vits_finetuned,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=456,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tp_size=0,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.01,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "weight_disc=3,\n",
            "weight_duration=1,\n",
            "weight_fmaps=1,\n",
            "weight_gen=1,\n",
            "weight_kl=1.5,\n",
            "weight_mel=35,\n",
            ")\n",
            "04/03/2025 18:02:28 - INFO - __main__ - Training/evaluation parameters VITSTrainingArguments(\n",
            "_n_gpu=0,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.8,\n",
            "adam_beta2=0.99,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_step_schedule_per_epoch=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=mms-tts-vie-own,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/tmp/vits_finetuned/runs/Apr03_18-02-26_b368657c305a,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_decay=0.999875,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=200,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/tmp/vits_finetuned,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/tmp/vits_finetuned,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=456,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tp_size=0,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.01,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "weight_disc=3,\n",
            "weight_duration=1,\n",
            "weight_fmaps=1,\n",
            "weight_gen=1,\n",
            "weight_kl=1.5,\n",
            "weight_mel=35,\n",
            ")\n",
            "README.md: 100% 493/493 [00:00<00:00, 2.66MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/finetune-hf-vits/run_vits_finetuning.py\", line 1494, in <module>\n",
            "    main()\n",
            "  File \"/content/finetune-hf-vits/run_vits_finetuning.py\", line 591, in main\n",
            "    raw_datasets[\"train\"] = load_dataset(\n",
            "                            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 2062, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/load.py\", line 1819, in load_dataset_builder\n",
            "    builder_instance: DatasetBuilder = builder_cls(\n",
            "                                       ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/builder.py\", line 343, in __init__\n",
            "    self.config, self.config_id = self._create_builder_config(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/datasets/builder.py\", line 570, in _create_builder_config\n",
            "    raise ValueError(\n",
            "ValueError: BuilderConfig 'own' not found. Available: ['default']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1194, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 780, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'run_vits_finetuning.py', 'finetune_vie_own.json']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GRiir05u0VB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}